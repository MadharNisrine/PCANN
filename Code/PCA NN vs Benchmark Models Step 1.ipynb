{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import KNeighborsClassifier #Supervised\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm # Supervised \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import load, save\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import Counter\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import numpy.linalg as npl\n",
    "#from decomp_utils import *\n",
    "#from pca_ad_utils1 import *\n",
    "from numpy import load,save \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "from sklearn.metrics import auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "import sys \n",
    "sys.path.append(r'C:\\Users\\nmadhar\\Desktop\\Conv_deep\\ToSubmit\\Code')\n",
    "from pca_ad_utils import *\n",
    "from decomp_utils import *\n",
    "from customizedLossSynthetic import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Data import \n",
    "\n",
    "Data used included volatilities, spread, rates ... \n",
    "\n",
    "The train and test samples are from years 2018/2019. Since the sliding window technique was used to augment the data a particular attention was brought to avoid having close time series at the same time in the training and test sample which could result in a bias in the final prediction and misevaluation of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal observations in train set 6010\n",
      "Outlier observations in train set 6010 \n",
      "\n",
      "Normal observations in test set 2109\n",
      "Outlier observations in test set 421\n"
     ]
    }
   ],
   "source": [
    "X_trainUnderdf = pd.read_csv(r'C:\\Users\\nmadhar\\Desktop\\Conv_deep\\ToSubmit\\Data\\XTrainUnder.csv').drop(['Unnamed: 0'],axis=1)\n",
    "y_trainUnderdf = pd.read_csv(r'C:\\Users\\nmadhar\\Desktop\\Conv_deep\\ToSubmit\\Data\\yTrainUnder.csv').drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "X_testUnderdf = pd.read_csv(r'C:\\Users\\nmadhar\\Desktop\\Conv_deep\\ToSubmit\\Data\\XTestUnder.csv').drop(['Unnamed: 0'],axis=1)\n",
    "y_testUnderdf = pd.read_csv(r'C:\\Users\\nmadhar\\Desktop\\Conv_deep\\ToSubmit\\Data\\yTestUnder.csv').drop(['Unnamed: 0'],axis=1)\n",
    "xtrain = np.array(X_trainUnderdf.iloc[:,:-3])\n",
    "xtest = np.array(X_testUnderdf.iloc[:,:-3])\n",
    "\n",
    "y_train = np.array(y_trainUnderdf['NbAnomaly'])\n",
    "y_test = np.array(y_testUnderdf['NbAnomaly'])\n",
    "ytrain = np.array([1 if l==1 else 0 for l in y_train])\n",
    "ytest = np.array([1 if l==1 else 0 for l in y_test])\n",
    "\n",
    "print(f'Normal observations in train set {list(y_train).count(0)}')\n",
    "print(f'Outlier observations in train set {list(y_train).count(1)} \\n')\n",
    "\n",
    "print(f'Normal observations in test set {list(y_test).count(0)}')\n",
    "print(f'Outlier observations in test set {list(y_test).count(1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = [1 if i==1 else 0 for i in ytrain]\n",
    "ytest = [1 if i==1 else 0 for i in ytest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb. anomalies in Train :6010\n",
      "Nb. normal in Train :6010 \n",
      "\n",
      "Nb. anomalies in Test :421\n",
      "Nb. normal in Test :2109 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Nb. anomalies in Train :{ytrain.count(1)}')\n",
    "print(f'Nb. normal in Train :{ytrain.count(0)} \\n')\n",
    "\n",
    "print(f'Nb. anomalies in Test :{ytest.count(1)}')\n",
    "print(f'Nb. normal in Test :{ytest.count(0)} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoresDFTrain = pd.DataFrame(columns=['Algo','Accuracy','Recall','Precision','F1'])\n",
    "ScoresDFTrain['Algo'] = ['IF','LOF','KNN','DBSCAN','SVM','PCA NN AD']\n",
    "ScoresDFTest = pd.DataFrame(columns=['Algo','Accuracy','Recall','Precision','F1'])\n",
    "ScoresDFTest['Algo'] = ['IF','LOF','KNN','DBSCAN','SVM','PCA NN AD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Testing classic anomaly detection algorithms  \n",
    "\n",
    "### 1. Isolation forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exe. time :0.6915252208709717\n",
      "\n",
      "Accuracy on Train : 0.42312811980033277\n",
      "Accuracy on Test : 0.6964426877470355\n",
      "\n",
      "Recall on Train : 0.42312811980033277\n",
      "Recall on Test : 0.0688836104513064\n",
      "\n",
      "Precsion on Train : 0.42312811980033277\n",
      "Precision on Test : 0.07160493827160494\n",
      "\n",
      "F1-score on Train : 0.42312811980033277\n",
      "F1-score on Test : 0.0702179176755448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with balanced training and unbalanced test\n",
    "clf_if_train = IsolationForest(random_state=0,contamination=0.5)\n",
    "\n",
    "ypredTrainIF = redefine_if_lof_pred(clf_if_train.fit_predict(xtrain))\n",
    "\n",
    "s = time.time()\n",
    "clf_if_test = IsolationForest(random_state=0,contamination=0.16)\n",
    "ypredTestIF = redefine_if_lof_pred(clf_if_test.fit_predict(xtest))\n",
    "timeIF  = time.time()-s\n",
    "print(f'Exe. time :{timeIF}\\n')\n",
    "\n",
    "scoresTrainIF = evalalg(ytrain,ypredTrainIF)\n",
    "scoresTestIF = evalalg(ytest,ypredTestIF)\n",
    "\n",
    "\n",
    "print(f'Accuracy on Train : {accuracy_score(ytrain,ypredTrainIF)}')\n",
    "print(f'Accuracy on Test : {accuracy_score(ytest,ypredTestIF)}\\n')\n",
    "\n",
    "print(f'Recall on Train : {recall_score(ytrain,ypredTrainIF)}')\n",
    "print(f'Recall on Test : {recall_score(ytest,ypredTestIF)}\\n')\n",
    "\n",
    "print(f'Precsion on Train : {precision_score(ytrain,ypredTrainIF)}')\n",
    "print(f'Precision on Test : {precision_score(ytest,ypredTestIF,pos_label=1)}\\n')\n",
    "\n",
    "print(f'F1-score on Train : {f1_score(ytrain,ypredTrainIF)}')\n",
    "print(f'F1-score on Test : {f1_score(ytest,ypredTestIF)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6010\n",
      "1    6010\n",
      "Name: target, dtype: int64\n",
      "0    2125\n",
      "1     405\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(ypredTrainIF,columns=['target'])['target'].value_counts())\n",
    "print(pd.DataFrame(ypredTestIF,columns=['target'])['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoresDFTrain.iloc[0,1:] =  scoresTrainIF\n",
    "ScoresDFTest.iloc[0,1:] =  scoresTestIF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Local Outlier factor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exe. time :0.201460599899292\n",
      "Accuracy on Train : 0.5995008319467554\n",
      "Accuracy on Test : 0.9\n",
      "Recall on Train : 0.5995008319467554\n",
      "Recall on Test : 0.498812351543943\n",
      "\n",
      "Precsion on Train : 0.5995008319467554\n",
      "Precision on Test : 0.8333333333333334\n",
      "\n",
      "F1-score on Train : 0.5995008319467554\n",
      "F1-score on Test : 0.6240713224368499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with balanced training and unbalanced test\n",
    "\n",
    "\n",
    "clf_lof_train = LocalOutlierFactor(n_neighbors=2,novelty= False,contamination=0.5)\n",
    "ypredTrainLOF = redefine_if_lof_pred(clf_lof_train.fit_predict(xtrain))\n",
    "\n",
    "s = time.time()\n",
    "clf_lof_test = LocalOutlierFactor(n_neighbors=2,novelty= False)\n",
    "ypredTestLOF = redefine_if_lof_pred(clf_lof_test.fit_predict(xtest))\n",
    "timeLOF  = time.time()-s\n",
    "\n",
    "print(f'Exe. time :{timeLOF}')\n",
    "\n",
    "print(f'Accuracy on Train : {accuracy_score(ytrain,ypredTrainLOF)}')\n",
    "print(f'Accuracy on Test : {accuracy_score(ytest,ypredTestLOF)}')\n",
    "\n",
    "\n",
    "print(f'Recall on Train : {recall_score(ytrain,ypredTrainLOF)}')\n",
    "print(f'Recall on Test : {recall_score(ytest,ypredTestLOF)}\\n')\n",
    "\n",
    "print(f'Precsion on Train : {precision_score(ytrain,ypredTrainLOF)}')\n",
    "print(f'Precision on Test : {precision_score(ytest,ypredTestLOF,pos_label=1)}\\n')\n",
    "\n",
    "print(f'F1-score on Train : {f1_score(ytrain,ypredTrainLOF)}')\n",
    "print(f'F1-score on Test : {f1_score(ytest,ypredTestLOF)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lof_train = LocalOutlierFactor(n_neighbors=2,novelty= False,contamination=0.5)\n",
    "clf_lof_test = LocalOutlierFactor(n_neighbors=2,novelty= False)\n",
    "\n",
    "ypredTrainLOF = redefine_if_lof_pred(clf_lof_train.fit_predict(xtrain))\n",
    "ypredTestLOF = redefine_if_lof_pred(clf_lof_test.fit_predict(xtest))\n",
    "\n",
    "\n",
    "scoresTrainLOF = evalalg(ytrain,ypredTrainLOF)\n",
    "scoresTestLOF = evalalg(ytest,ypredTestLOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5995008319467554, 0.5995008319467554, 0.5995008319467554, 0.5995008319467554)\n",
      "(0.9, 0.498812351543943, 0.8333333333333334, 0.6240713224368499)\n"
     ]
    }
   ],
   "source": [
    "print(scoresTrainLOF)\n",
    "print(scoresTestLOF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6010\n",
      "0    6010\n",
      "Name: target, dtype: int64\n",
      "0    2278\n",
      "1     252\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(ypredTrainLOF,columns=['target'])['target'].value_counts())\n",
    "print(pd.DataFrame(ypredTestLOF,columns=['target'])['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoresDFTrain.iloc[1,1:] =  scoresTrainLOF\n",
    "ScoresDFTest.iloc[1,1:] =  scoresTestLOF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. K nearest neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exe. time :1.725247859954834\n",
      "Accuracy on Train : 0.9468386023294509\n",
      "Accuracy on Test : 0.6482213438735178\n",
      "Recall on Train : 0.8936772046589019\n",
      "Recall on Test : 0.3847980997624703\n",
      "\n",
      "Precsion on Train : 1.0\n",
      "Precision on Test : 0.2042875157629256\n",
      "\n",
      "F1-score on Train : 0.9438537914067305\n",
      "F1-score on Test : 0.2668863261943987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "clf_knn.fit(xtrain,ytrain)\n",
    "\n",
    "ypredTrainKNN = clf_knn.predict(xtrain)\n",
    "\n",
    "s = time.time()\n",
    "ypredTestKNN = clf_knn.predict(xtest)\n",
    "timeKNN  = time.time()-s\n",
    "\n",
    "print(f'Exe. time :{timeKNN}')\n",
    "\n",
    "print(f'Accuracy on Train : {accuracy_score(ytrain,ypredTrainKNN)}')\n",
    "print(f'Accuracy on Test : {accuracy_score(ytest,ypredTestKNN)}')\n",
    "\n",
    "print(f'Recall on Train : {recall_score(ytrain,ypredTrainKNN)}')\n",
    "print(f'Recall on Test : {recall_score(ytest,ypredTestKNN)}\\n')\n",
    "\n",
    "print(f'Precsion on Train : {precision_score(ytrain,ypredTrainKNN)}')\n",
    "print(f'Precision on Test : {precision_score(ytest,ypredTestKNN,pos_label=1)}\\n')\n",
    "\n",
    "print(f'F1-score on Train : {f1_score(ytrain,ypredTrainKNN)}')\n",
    "print(f'F1-score on Test : {f1_score(ytest,ypredTestKNN)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "clf_knn.fit(xtrain,ytrain)\n",
    "\n",
    "ypredTrainKNN = clf_knn.predict(xtrain)\n",
    "ypredTestKNN = clf_knn.predict(xtest)\n",
    "\n",
    "\n",
    "\n",
    "scoresTrainKNN = evalalg(ytrain,ypredTrainKNN)\n",
    "scoresTestKNN = evalalg(ytest,ypredTestKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9468386023294509, 0.8936772046589019, 1.0, 0.9438537914067305)\n",
      "(0.6482213438735178, 0.3847980997624703, 0.2042875157629256, 0.2668863261943987)\n"
     ]
    }
   ],
   "source": [
    "print(scoresTrainKNN)\n",
    "print(scoresTestKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6649\n",
      "1    5371\n",
      "Name: target, dtype: int64\n",
      "0    1737\n",
      "1     793\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(ypredTrainKNN,columns=['target'])['target'].value_counts())\n",
    "print(pd.DataFrame(ypredTestKNN,columns=['target'])['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoresDFTrain.iloc[2,1:] =  scoresTrainKNN\n",
    "ScoresDFTest.iloc[2,1:] =  scoresTestKNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. DBSCAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exe. time :0.12747907638549805\n",
      "Accuracy on Train : 0.5\n",
      "Accuracy on Test : 0.16640316205533598\n",
      "Recall on Train : 1.0\n",
      "Recall on Test : 1.0\n",
      "\n",
      "Precsion on Train : 0.5\n",
      "Precision on Test : 0.16640316205533598\n",
      "\n",
      "F1-score on Train : 0.6666666666666666\n",
      "F1-score on Test : 0.2853270077939682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf_dbscan_train = DBSCAN(eps = .2, \n",
    " metric='euclidean', \n",
    " min_samples = 2,\n",
    " n_jobs = -1).fit_predict(xtrain)\n",
    "ypredTrainDBSCAN = list(clf_dbscan_train)\n",
    "\n",
    "\n",
    "s = time.time()\n",
    "clf_dbscan_test = DBSCAN(eps = .2, \n",
    " metric='euclidean', \n",
    " min_samples = 2,\n",
    " n_jobs = -1).fit_predict(xtest)\n",
    "\n",
    "ypredTestDBSCAN = list(clf_dbscan_test)\n",
    "timeDBSCAN  = time.time()-s\n",
    "\n",
    "print(f'Exe. time :{timeDBSCAN}')\n",
    "\n",
    "\n",
    "ypredTrainDBSCAN  =  redefine_pred_DBSCAN(ypredTrainDBSCAN)\n",
    "ypredTestDBSCAN  =  redefine_pred_DBSCAN(ypredTestDBSCAN)\n",
    "\n",
    "print(f'Accuracy on Train : {accuracy_score(ytrain,ypredTrainDBSCAN)}')\n",
    "print(f'Accuracy on Test : {accuracy_score(ytest,ypredTestDBSCAN)}')\n",
    "\n",
    "print(f'Recall on Train : {recall_score(ytrain,ypredTrainDBSCAN)}')\n",
    "print(f'Recall on Test : {recall_score(ytest,ypredTestDBSCAN)}\\n')\n",
    "\n",
    "print(f'Precsion on Train : {precision_score(ytrain,ypredTrainDBSCAN)}')\n",
    "print(f'Precision on Test : {precision_score(ytest,ypredTestDBSCAN,pos_label=1)}\\n')\n",
    "\n",
    "print(f'F1-score on Train : {f1_score(ytrain,ypredTrainDBSCAN)}')\n",
    "print(f'F1-score on Test : {f1_score(ytest,ypredTestDBSCAN)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dbscan_train = DBSCAN(eps = .2, \n",
    " metric='euclidean', \n",
    " min_samples = 2,\n",
    " n_jobs = -1).fit_predict(xtrain)\n",
    "\n",
    "clf_dbscan_test = DBSCAN(eps = .2, \n",
    " metric='euclidean', \n",
    " min_samples = 2,\n",
    " n_jobs = -1).fit_predict(xtest)\n",
    "\n",
    "ypredTrainDBSCAN = list(clf_dbscan_train)\n",
    "ypredTestDBSCAN = list(clf_dbscan_test)\n",
    "ypredTrainDBSCAN  =  redefine_pred_DBSCAN(ypredTrainDBSCAN)\n",
    "ypredTestDBSCAN  =  redefine_pred_DBSCAN(ypredTestDBSCAN)\n",
    "\n",
    "scoresTrainDBSCAN = evalalg(ytrain,ypredTrainDBSCAN)\n",
    "scoresTestDBSCAN = evalalg(ytest,ypredTestDBSCAN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5, 1.0, 0.5, 0.6666666666666666)\n",
      "(0.16640316205533598, 1.0, 0.16640316205533598, 0.2853270077939682)\n"
     ]
    }
   ],
   "source": [
    "print(scoresTrainDBSCAN)\n",
    "print(scoresTestDBSCAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    12020\n",
      "Name: target, dtype: int64\n",
      "1    2530\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(ypredTrainDBSCAN,columns=['target'])['target'].value_counts())\n",
    "print(pd.DataFrame(ypredTestDBSCAN,columns=['target'])['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoresDFTrain.iloc[3,1:] =  scoresTrainDBSCAN\n",
    "ScoresDFTest.iloc[3,1:] =  scoresTestDBSCAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exe. time :4.5726470947265625\n",
      "Accuracy on Train : 0.8196339434276206\n",
      "Accuracy on Test : 0.44387351778656126\n",
      "Recall on Train : 0.840432612312812\n",
      "Recall on Test : 0.6318289786223278\n",
      "\n",
      "Precsion on Train : 0.8068690095846646\n",
      "Precision on Test : 0.17523056653491437\n",
      "\n",
      "F1-score on Train : 0.8233088834555827\n",
      "F1-score on Test : 0.2743682310469314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC()\n",
    "clf_svm.fit(xtrain,ytrain)\n",
    "ypredTrainSVM = clf_svm.predict(xtrain)\n",
    "s = time.time()\n",
    "ypredTestSVM = clf_svm.predict(xtest)\n",
    "timeSVM  = time.time()-s\n",
    "\n",
    "print(f'Exe. time :{timeSVM}')\n",
    "\n",
    "\n",
    "print(f'Accuracy on Train : {accuracy_score(ytrain,ypredTrainSVM)}' )\n",
    "print(f'Accuracy on Test : {accuracy_score(ytest,ypredTestSVM)}' )\n",
    "\n",
    "print(f'Recall on Train : {recall_score(ytrain,ypredTrainSVM)}')\n",
    "print(f'Recall on Test : {recall_score(ytest,ypredTestSVM)}\\n')\n",
    "\n",
    "print(f'Precsion on Train : {precision_score(ytrain,ypredTrainSVM)}')\n",
    "print(f'Precision on Test : {precision_score(ytest,ypredTestSVM,pos_label=1)}\\n')\n",
    "\n",
    "print(f'F1-score on Train : {f1_score(ytrain,ypredTrainSVM)}')\n",
    "print(f'F1-score on Test : {f1_score(ytest,ypredTestSVM)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = svm.SVC()\n",
    "clf_svm.fit(xtrain,ytrain)\n",
    "ypredTrainSVM = clf_svm.predict(xtrain)\n",
    "ypredTestSVM = clf_svm.predict(xtest)\n",
    "\n",
    "scoresTrainSVM = evalalg(ytrain,ypredTrainSVM)\n",
    "scoresTestSVM = evalalg(ytest,ypredTestSVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8196339434276206, 0.840432612312812, 0.8068690095846646, 0.8233088834555827)\n",
      "(0.44387351778656126, 0.6318289786223278, 0.17523056653491437, 0.2743682310469314)\n"
     ]
    }
   ],
   "source": [
    "print(scoresTrainSVM)\n",
    "print(scoresTestSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6260\n",
      "0    5760\n",
      "Name: target, dtype: int64\n",
      "1    1518\n",
      "0    1012\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(ypredTrainSVM,columns=['target'])['target'].value_counts())\n",
    "print(pd.DataFrame(ypredTestSVM,columns=['target'])['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoresDFTrain.iloc[4,1:] =  scoresTrainSVM\n",
    "ScoresDFTest.iloc[4,1:] =  scoresTestSVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. PCA NN AD  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CalibParamsLoaded = load(r'C:\\Users\\nmadhar\\Desktop\\Conv_deep\\ToSubmit\\Results\\Model\\CalibParams2405_2.pkl',allow_pickle=True)\n",
    "netLoaded = NeuralNetwork()\n",
    "netLoaded.load_state_dict(torch.load(r'C:\\Users\\nmadhar\\Desktop\\Conv_deep\\ToSubmit\\Results\\Model\\modelCustomLoss2405_2.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "\n",
    "# Learning on TS \n",
    "\n",
    "model = PCA(n_components=k)\n",
    "model.fit(xtrain)\n",
    "r_train = model.inverse_transform(model.transform(xtrain))\n",
    "r_test = model.inverse_transform(model.transform(xtest))\n",
    "\n",
    "\n",
    "reconsRawTrain = r_train\n",
    "reconsRawTest = r_test\n",
    "\n",
    "\n",
    "reconsRawTrain = torch.tensor(reconsRawTrain)\n",
    "ytrain = torch.tensor(y_train.reshape(-1,1))\n",
    "\n",
    "\n",
    "reconsRawTest = torch.tensor(reconsRawTest)\n",
    "ytest = torch.tensor(y_test.reshape(-1,1))\n",
    "xtrain = np.array(xtrain,dtype=float)\n",
    "ytrain = np.array(y_train,dtype=float)\n",
    "\n",
    "xtest = np.array(xtest,dtype=float)\n",
    "ytest = np.array(y_test,dtype=float)\n",
    "\n",
    "xtrain = torch.tensor(xtrain)\n",
    "ytrain = torch.tensor(ytrain.reshape(-1,1))\n",
    "\n",
    "\n",
    "xtest = torch.tensor(xtest)\n",
    "ytest = torch.tensor(ytest.reshape(-1,1))\n",
    "\n",
    "ErrRawTrain = xtrain - reconsRawTrain\n",
    "ErrRawTrain = torch.tensor(ErrRawTrain)\n",
    "\n",
    "ErrRawTest = xtest - reconsRawTest\n",
    "ErrRawTest = torch.tensor(ErrRawTest)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exe. time :0.0035233497619628906\n"
     ]
    }
   ],
   "source": [
    "anomalyScoresTrain = netLoaded(ErrRawTrain.type(torch.FloatTensor))\n",
    "s = time.time()\n",
    "anomalyScoresTest = netLoaded(ErrRawTest.type(torch.FloatTensor))\n",
    "timePCANN  = time.time()-s\n",
    "\n",
    "print(f'Exe. time :{timePCANN}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Scores on Train set-------------------\n",
      "Accuracy :  0.9097\n",
      "Precision :  0.9736\n",
      "Recall :  0.8421\n",
      "F1-score: 0.9031\n",
      "\n",
      "\n",
      "-------------------Scores on Test set-------------------\n",
      "Accuracy :  0.8858\n",
      "Precision :  0.6126\n",
      "Recall :  0.8527\n",
      "F1-score: 0.7130\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "STrain,scoresTrain  = evalPerf(netLoaded,ErrRawTrain,ytrain,'Train',CalibParamsLoaded)\n",
    "ScoresPCANNTrain = [scoresTrain[0],scoresTrain[2],scoresTrain[1],scoresTrain[-1]]\n",
    "\n",
    "STest,scoresTest  = evalPerf(netLoaded,ErrRawTest,ytest,'Test',CalibParamsLoaded)\n",
    "ScoresPCANNTest = [scoresTest[0],scoresTest[2],scoresTest[1],scoresTest[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredTrain = torch.tensor([1 if s > CalibParamsLoaded['That'] else 0 for s in STrain])\n",
    "PredTest = torch.tensor([1 if s > CalibParamsLoaded['That'] else 0 for s in STest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6822\n",
      "1    5198\n",
      "Name: target, dtype: int64\n",
      "0    1944\n",
      "1     586\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(PredTrain,columns=['target'])['target'].value_counts())\n",
    "print(pd.DataFrame(PredTest,columns=['target'])['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoresDFTrain.iloc[5,1:] =  ScoresPCANNTrain\n",
    "ScoresDFTest.iloc[5,1:] =  ScoresPCANNTest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IF</td>\n",
       "      <td>0.423128</td>\n",
       "      <td>0.423128</td>\n",
       "      <td>0.423128</td>\n",
       "      <td>0.423128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOF</td>\n",
       "      <td>0.599501</td>\n",
       "      <td>0.599501</td>\n",
       "      <td>0.599501</td>\n",
       "      <td>0.599501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.946839</td>\n",
       "      <td>0.893677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DBSCAN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.819634</td>\n",
       "      <td>0.840433</td>\n",
       "      <td>0.806869</td>\n",
       "      <td>0.823309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCA NN AD</td>\n",
       "      <td>0.909651</td>\n",
       "      <td>0.842097</td>\n",
       "      <td>0.973644</td>\n",
       "      <td>0.903105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Algo  Accuracy    Recall Precision        F1\n",
       "0         IF  0.423128  0.423128  0.423128  0.423128\n",
       "1        LOF  0.599501  0.599501  0.599501  0.599501\n",
       "2        KNN  0.946839  0.893677       1.0  0.943854\n",
       "3     DBSCAN       0.5       1.0       0.5  0.666667\n",
       "4        SVM  0.819634  0.840433  0.806869  0.823309\n",
       "5  PCA NN AD  0.909651  0.842097  0.973644  0.903105"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ScoresDFTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IF</td>\n",
       "      <td>0.696443</td>\n",
       "      <td>0.068884</td>\n",
       "      <td>0.071605</td>\n",
       "      <td>0.070218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOF</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.498812</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.624071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.648221</td>\n",
       "      <td>0.384798</td>\n",
       "      <td>0.204288</td>\n",
       "      <td>0.266886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DBSCAN</td>\n",
       "      <td>0.166403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166403</td>\n",
       "      <td>0.285327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.443874</td>\n",
       "      <td>0.631829</td>\n",
       "      <td>0.175231</td>\n",
       "      <td>0.274368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCA NN AD</td>\n",
       "      <td>0.885771</td>\n",
       "      <td>0.852732</td>\n",
       "      <td>0.612628</td>\n",
       "      <td>0.713009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Algo  Accuracy    Recall Precision        F1\n",
       "0         IF  0.696443  0.068884  0.071605  0.070218\n",
       "1        LOF       0.9  0.498812  0.833333  0.624071\n",
       "2        KNN  0.648221  0.384798  0.204288  0.266886\n",
       "3     DBSCAN  0.166403       1.0  0.166403  0.285327\n",
       "4        SVM  0.443874  0.631829  0.175231  0.274368\n",
       "5  PCA NN AD  0.885771  0.852732  0.612628  0.713009"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ScoresDFTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6915252208709717,\n",
       " 0.201460599899292,\n",
       " 0.12747907638549805,\n",
       " 1.725247859954834,\n",
       " 4.5726470947265625,\n",
       " 0.0035233497619628906]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[timeIF,timeLOF,timeDBSCAN,timeKNN,timeSVM,timePCANN]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
